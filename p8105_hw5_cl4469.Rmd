---
title: "p8105_hw5_cl4469"
author: "Chen Liang"
date: "2023-11-12"
output: github_document
---

```{r}
library(tidyverse)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "95%"
)

theme_set(theme_minimal() + theme(legend.position = 'bottom'))

options(
  ggplot2.continuous.colour = 'viridis',
  ggplot2.continuous.fill = 'viridis'
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
```{r, load data}
homicide_df = read.csv("hw5_data/homicide-data.csv")
```
This dataset contains `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns, with each row resprenting a single event occurred. Variables include id, reported-date, victims'last name,race, and sex. It contains the location of the killing (city, state, latitude, longitude) and whether an arrest was made. Moreover, there are some missing values in `lat` and `lon` columns and unknown information in `victim_last`,`victim_first`,`victim_age`,`victim_sex`, and `victim_race`.

```{r}
hom_summary = homicide_df|>
  mutate(
    city_state = str_c(city, state, sep = ","),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )) |>
  group_by(city_state) |>
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved"),
    home_solved = sum(resolved == "solved")
  )

hom_summary
```

```{r,prop test for Baltimore,MD}
res_tidy = prop.test(
  hom_summary |>filter(city_state == "Baltimore,MD") |> pull(hom_unsolved), 
  hom_summary |>filter(city_state == "Baltimore,MD") |> pull(hom_total)) |>
  broom::tidy(res_tidy)

save(res_tidy, file = "result/prop_test_MD.RData")
```

Pull the estimated proportion and confidence intervals from the resulting tidy dataframe
```{r}
estimated_prop=pull(res_tidy, estimate)
ci=paste("(", pull(res_tidy, conf.low),",", pull(res_tidy, conf.high),")")
```

```{r,make a plot}
results_df = 
  hom_summary %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

# Problem 2
First, we create a dataframe and read in data for each subject.
```{r}
file_name =
  list.files("hw5_data/data/", full.names = TRUE)

prob2_df= file_name |>
  map_dfr(read_csv)|>
  bind_cols(name = file_name)
```

Next, we tidy the result.
```{r}
tidy_prob2_df =
  prob2_df|> 
  mutate(arm = 
           case_when(
             str_detect(name, "con") ~ "control",
             str_detect(name, "exp") ~ "experimental"),
         id = str_sub(name, 20, 21)
         ) |>
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "observations",
               names_prefix = "week_") |> 
  mutate(week = as.numeric(week))|>
  dplyr::select(id, arm, week, observations)
```

Make a spaghetti plot showing observations on each subject over time.
```{r}
tidy_prob2_df |>
  ggplot(aes(x = week, y = observations, color = id)) +
  geom_point()+
  geom_line() +
  facet_grid(~arm) +
  geom_smooth(aes(group = 1), se = FALSE, color = "red") +
  labs(x = 'Week', y = 'Observations', title = 'Spaghetti Plot of Observations on Each Subject Over Time')

ggsave("result/Spaghetti Plot of Observations on Each Subject Over Time.pdf")
```
Comment:
From the spaghetti plot, the data values of the experimental group seem to be generally greater than those of the control group. We also observe a gentle variation in values over time within the control arm, whereas the experimental arm consistently demonstrates higher values than those in the control arm, with a tendency to increase over time.

# Problem 3
Fix n=30
Fix σ=5
```{r}
t_test = function(mu, n = 30, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
    )
  
  sim_result = broom::tidy(t.test(sim_data))
  sim_result |> 
    dplyr::select(estimate, p.value)
}

sim_results_df = 
  expand_grid(
    mu = 0,
    iter = 1:5000
    )|>
  mutate(
    estimate_df = map(mu, t_test)
    ) |> 
  unnest(estimate_df) |>
  rename("p_value" = "p.value")

sim_results_df
```

Repeat the above for mu=1,2,3,4,5,6, and complete the following:
```{r}
new_results_df = 
  expand_grid(
    mu = c(1,2,3,4,5,6),
    iter = 1:5000
  ) |> 
  mutate(
    estimate_df = map(mu, t_test)
  ) |> 
  unnest(estimate_df) |>
  rename("p_value" = "p.value")

```

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis
```{r}
all_result_df= bind_rows(sim_results_df, new_results_df)

power_df =
  all_result_df |> 
  mutate(reject = case_when(
    p_value > 0.05 ~ FALSE,
    p_value < 0.05 ~ TRUE
  )) |> 
  group_by(mu) |> 
  summarise(count = sum(reject)) |> 
  mutate(prop_rejext = count / 5000)

power_df |> 
  ggplot(aes(x = mu, y = prop_rejext)) +
  geom_point() +
  geom_line() +
  labs(title = "Proportiobn of Rejected Hypotheses for each Mu",
       x = "True Value of Mu", y = "Proportion Rejected")
```

